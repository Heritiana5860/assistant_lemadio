from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
import json
import datetime
import os
from dotenv import load_dotenv
from rag_search import RAGSearcher

# Charger les variables d'environnement
load_dotenv()

# Cr√©er l'application Flask
app = Flask(__name__)

# Activer CORS (permet √† Flutter de communiquer)
CORS(app)

# ============== CONFIGURATION ==============

# URL de Ollama (locale par d√©faut)
OLLAMA_URL = os.getenv('OLLAMA_URL', 'http://localhost:11434')
OLLAMA_MODEL = 'mistral'

# System prompt : c'est les "instructions" qu'on donne √† Mistral
SYSTEM_PROMPT = """Tu es un assistant d'aide pour l'application mobile ADES.
Tu aides les vendeurs √† utiliser l'application de vente ADES.

R√àGLES IMPORTANTES :
- Base tes r√©ponses UNIQUEMENT sur la documentation fournie ci-dessous
- Sois pr√©cis, clair et concis
- R√©ponds en fran√ßais ou malagasy selon la question
- Si tu ne trouves pas l'information dans la documentation, dis-le honn√™tement
- Donne des instructions √©tape par √©tape quand c'est appropri√©
- Si la question n'est pas sur l'app ADES, dis poliment que tu ne peux pas aider"""

# Cr√©er le dossier logs s'il n'existe pas
if not os.path.exists('logs'):
    os.makedirs('logs')

# ============== INITIALISATION RAG ==============

print("\n" + "="*60)
print("üöÄ D√âMARRAGE DU BACKEND ADES CHATBOT")
print("="*60)

# Initialiser le RAG Searcher
try:
    rag_searcher = RAGSearcher(data_dir='rag/data')
    RAG_ENABLED = True
    print("‚úÖ RAG activ√© et pr√™t")
except Exception as e:
    print(f"‚ö†Ô∏è  RAG d√©sactiv√© : {e}")
    print("   Le chatbot fonctionnera sans contexte personnalis√©")
    rag_searcher = None
    RAG_ENABLED = False

print("="*60 + "\n")

# ============== FONCTIONS UTILITAIRES ==============

def log_conversation(user_message, bot_response, context_used=None):
    """
    Sauvegarde chaque conversation dans un fichier log
    pour pouvoir analyser plus tard
    """
    timestamp = datetime.datetime.now().isoformat()
    log_entry = {
        'timestamp': timestamp,
        'user': user_message,
        'bot': bot_response,
        'context_used': context_used is not None,
        'rag_enabled': RAG_ENABLED
    }
    
    log_file = 'logs/conversations.jsonl'
    
    try:
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    except Exception as e:
        print(f"Erreur lors du logging: {e}")

def call_ollama(prompt, temperature=0.3):
    """
    Appelle Ollama (Mistral) avec le prompt fourni
    Retourne la r√©ponse
    """
    try:
        # Pr√©parer la requ√™te pour Ollama
        payload = {
            'model': OLLAMA_MODEL,
            'prompt': prompt,
            'stream': False,
            'temperature': temperature
        }
        
        # Appeler l'API Ollama
        response = requests.post(
            f'{OLLAMA_URL}/api/generate',
            json=payload,
            timeout=60  # Timeout apr√®s 60 secondes
        )
        
        # V√©rifier si l'appel a r√©ussi
        if response.status_code == 200:
            result = response.json()
            return result.get('response', 'Erreur: pas de r√©ponse')
        else:
            return f'Erreur Ollama: {response.status_code}'
            
    except requests.exceptions.ConnectionError:
        return 'Erreur: Impossible de se connecter √† Ollama. V√©rifiez que Ollama fonctionne (ollama serve)'
    except requests.exceptions.Timeout:
        return 'Erreur: Ollama a mis trop de temps √† r√©pondre'
    except Exception as e:
        return f'Erreur: {str(e)}'

def create_prompt_with_context(user_message, context):
    """
    Cr√©e le prompt complet avec le contexte RAG
    """
    prompt = f"""{SYSTEM_PROMPT}

DOCUMENTATION ADES (extraits pertinents) :
---
{context}
---

QUESTION DU VENDEUR : {user_message}

R√âPONSE (bas√©e uniquement sur la documentation ci-dessus) :"""
    
    return prompt

def create_prompt_without_context(user_message):
    """
    Cr√©e le prompt sans contexte (fallback si RAG d√©sactiv√©)
    """
    prompt = f"""{SYSTEM_PROMPT}

QUESTION : {user_message}

R√âPONSE :"""
    
    return prompt

# ============== ROUTES API ==============

@app.route('/', methods=['GET'])
def home():
    """
    Route simple pour v√©rifier que le serveur fonctionne
    """
    return jsonify({
        'status': 'ok',
        'message': 'Backend ADES ChatBot fonctionne!',
        'version': '2.0.0',
        'rag_enabled': RAG_ENABLED
    })

@app.route('/api/health', methods=['GET'])
def health():
    """
    V√©rifie la sant√© du serveur et la connexion √† Ollama
    """
    try:
        # Essayer de se connecter √† Ollama
        response = requests.get(f'{OLLAMA_URL}/api/tags', timeout=5)
        ollama_status = 'connected' if response.status_code == 200 else 'disconnected'
    except:
        ollama_status = 'disconnected'
    
    # V√©rifier le statut du RAG
    rag_status = 'disabled'
    if RAG_ENABLED and rag_searcher:
        rag_health = rag_searcher.health_check()
        rag_status = rag_health.get('status', 'error')
    
    return jsonify({
        'backend': 'running',
        'ollama': ollama_status,
        'rag': rag_status,
        'timestamp': datetime.datetime.now().isoformat()
    })

@app.route('/api/chat', methods=['POST'])
def chat():
    """
    Route principale pour le chatbot avec RAG
    Re√ßoit une question, cherche dans la doc, appelle Mistral, retourne la r√©ponse
    """
    try:
        # R√©cup√©rer le message de la requ√™te
        data = request.get_json()
        user_message = data.get('message', '')
        
        # Valider que le message n'est pas vide
        if not user_message or len(user_message.strip()) == 0:
            return jsonify({
                'error': 'Le message ne peut pas √™tre vide'
            }), 400
        
        # Variable pour stocker le contexte utilis√©
        context_used = None
        
        # Cr√©er le prompt avec ou sans RAG
        if RAG_ENABLED and rag_searcher:
            # Rechercher le contexte pertinent
            print(f"üîç Recherche RAG pour : {user_message[:50]}...")
            context = rag_searcher.get_context(user_message, top_k=3, max_length=2000)
            context_used = context
            
            # Cr√©er le prompt avec contexte
            full_prompt = create_prompt_with_context(user_message, context)
            print(f"‚úÖ Contexte trouv√© ({len(context)} caract√®res)")
        else:
            # Fallback sans RAG
            full_prompt = create_prompt_without_context(user_message)
            print(f"‚ö†Ô∏è  Pas de RAG, utilisation du prompt basique")
        
        # Appeler Ollama
        print(f"ü§ñ Appel √† Mistral...")
        bot_response = call_ollama(full_prompt)
        print(f"‚úÖ R√©ponse re√ßue")
        
        # Logger la conversation
        log_conversation(user_message, bot_response, context_used)
        
        # Pr√©parer la r√©ponse
        response_data = {
            'status': 'success',
            'user_message': user_message,
            'reply': bot_response,
            'rag_used': RAG_ENABLED and context_used is not None,
            'timestamp': datetime.datetime.now().isoformat()
        }
        
        # Ajouter le contexte si demand√© (pour d√©boguer)
        if data.get('include_context', False) and context_used:
            response_data['context'] = context_used
        
        return jsonify(response_data)
        
    except Exception as e:
        print(f"‚ùå Erreur dans /api/chat : {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/search', methods=['POST'])
def search():
    """
    Route pour tester la recherche RAG directement
    Utile pour d√©boguer
    """
    try:
        if not RAG_ENABLED or not rag_searcher:
            return jsonify({
                'error': 'RAG non disponible'
            }), 503
        
        data = request.get_json()
        query = data.get('query', '')
        top_k = data.get('top_k', 3)
        
        if not query:
            return jsonify({
                'error': 'Query manquante'
            }), 400
        
        # Rechercher
        results = rag_searcher.get_detailed_results(query, top_k=top_k)
        
        return jsonify({
            'query': query,
            'results': results,
            'count': len(results)
        })
        
    except Exception as e:
        return jsonify({
            'error': str(e)
        }), 500

@app.route('/api/logs', methods=['GET'])
def get_logs():
    """
    Route pour r√©cup√©rer les logs de conversation
    Utile pour d√©boguer et analyser
    """
    try:
        logs = []
        log_file = 'logs/conversations.jsonl'
        
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        logs.append(json.loads(line))
        
        return jsonify({
            'total': len(logs),
            'logs': logs[-50:]  # Retourner les 50 derniers logs
        })
        
    except Exception as e:
        return jsonify({
            'error': str(e)
        }), 500

# ============== GESTION ERREURS ==============

@app.errorhandler(404)
def not_found(error):
    """G√®re les routes non trouv√©es"""
    return jsonify({
        'error': 'Route non trouv√©e',
        'path': request.path
    }), 404

@app.errorhandler(500)
def server_error(error):
    """G√®re les erreurs du serveur"""
    return jsonify({
        'error': 'Erreur du serveur',
        'message': str(error)
    }), 500

# ============== MAIN ==============

if __name__ == '__main__':
    print("üöÄ D√©marrage du backend ADES ChatBot...")
    print(f"üì° Connect√© √† Ollama: {OLLAMA_URL}")
    print(f"ü§ñ Mod√®le: {OLLAMA_MODEL}")
    print(f"üîç RAG: {'Activ√©' if RAG_ENABLED else 'D√©sactiv√©'}")
    print("\nLe serveur d√©marre sur http://localhost:3000")
    print("Appuyez sur Ctrl+C pour arr√™ter\n")
    
    # Lancer le serveur
    app.run(debug=True, host='0.0.0.0', port=3000)