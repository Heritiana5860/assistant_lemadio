"""
Script pour crÃ©er les embeddings de la documentation ADES
et les stocker dans FAISS pour la recherche sÃ©mantique
"""

from sentence_transformers import SentenceTransformer
import faiss
import pickle
import numpy as np
import os

# ============== CONFIGURATION ==============

# Chemin vers la documentation
DOC_PATH = 'docs/ADES_DOCUMENTATION.md'

# Dossier de sortie pour les fichiers gÃ©nÃ©rÃ©s
OUTPUT_DIR = 'rag/data'

# ModÃ¨le d'embedding (multilangue, bon pour franÃ§ais/malagasy)
EMBEDDING_MODEL = 'all-MiniLM-L6-v2'

# Taille des chunks (en caractÃ¨res approximatif)
CHUNK_SIZE = 500

# ============== FONCTIONS ==============

def load_documentation(file_path):
    """
    Charge la documentation depuis le fichier Markdown
    """
    print(f"ğŸ“– Chargement de la documentation depuis {file_path}...")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"âœ… Documentation chargÃ©e ({len(content)} caractÃ¨res)")
        return content
    except FileNotFoundError:
        print(f"âŒ Erreur : Fichier {file_path} introuvable")
        return None
    except Exception as e:
        print(f"âŒ Erreur lors du chargement : {e}")
        return None

def split_into_chunks(text, chunk_size=500):
    """
    DÃ©coupe le texte en chunks intelligents
    
    StratÃ©gie :
    1. D'abord par sections (## ou ###)
    2. Puis par paragraphes si trop grand
    3. Garde un peu de contexte entre chunks
    """
    print(f"âœ‚ï¸  DÃ©coupage en chunks de ~{chunk_size} caractÃ¨res...")
    
    chunks = []
    
    # SÃ©parer par les titres de sections
    sections = text.split('\n## ')
    
    for i, section in enumerate(sections):
        if i > 0:  # Rajouter ## sauf pour le premier
            section = '## ' + section
        
        # Si la section est trop grande, la dÃ©couper par paragraphes
        if len(section) > chunk_size * 2:
            paragraphs = section.split('\n\n')
            current_chunk = ""
            
            for para in paragraphs:
                # Si ajouter ce paragraphe dÃ©passe la limite
                if len(current_chunk) + len(para) > chunk_size and current_chunk:
                    chunks.append(current_chunk.strip())
                    # Garder un peu de contexte (overlap)
                    current_chunk = para
                else:
                    current_chunk += "\n\n" + para if current_chunk else para
            
            # Ajouter le dernier chunk
            if current_chunk:
                chunks.append(current_chunk.strip())
        else:
            # La section est assez petite, on la garde entiÃ¨re
            if section.strip():
                chunks.append(section.strip())
    
    # Filtrer les chunks trop petits (moins de 50 caractÃ¨res)
    chunks = [c for c in chunks if len(c) > 50]
    
    print(f"âœ… {len(chunks)} chunks crÃ©Ã©s")
    
    # Afficher quelques exemples
    print("\nğŸ“ Exemples de chunks crÃ©Ã©s :")
    for i, chunk in enumerate(chunks[:3]):
        preview = chunk[:100].replace('\n', ' ')
        print(f"  Chunk {i+1}: {preview}...")
    
    return chunks

def create_embeddings(chunks, model_name):
    """
    CrÃ©e les embeddings pour chaque chunk
    """
    print(f"\nğŸ¤– Chargement du modÃ¨le d'embedding : {model_name}...")
    
    try:
        model = SentenceTransformer(model_name)
        print(f"âœ… ModÃ¨le chargÃ©")
    except Exception as e:
        print(f"âŒ Erreur lors du chargement du modÃ¨le : {e}")
        return None, None
    
    print(f"ğŸ”¢ CrÃ©ation des embeddings pour {len(chunks)} chunks...")
    print("â³ Cela peut prendre 1-2 minutes...")
    
    try:
        # Encoder tous les chunks en une fois
        embeddings = model.encode(chunks, show_progress_bar=True)
        
        print(f"âœ… Embeddings crÃ©Ã©s : {embeddings.shape}")
        print(f"   - Nombre de chunks : {embeddings.shape[0]}")
        print(f"   - Dimension des vecteurs : {embeddings.shape[1]}")
        
        return embeddings, model
    except Exception as e:
        print(f"âŒ Erreur lors de la crÃ©ation des embeddings : {e}")
        return None, None

def create_faiss_index(embeddings):
    """
    CrÃ©e un index FAISS pour la recherche rapide
    """
    print(f"\nğŸ—„ï¸  CrÃ©ation de l'index FAISS...")
    
    try:
        # Dimension des vecteurs
        dimension = embeddings.shape[1]
        
        # CrÃ©er un index simple (L2 distance)
        index = faiss.IndexFlatL2(dimension)
        
        # Ajouter les embeddings Ã  l'index
        index.add(embeddings.astype('float32'))
        
        print(f"âœ… Index FAISS crÃ©Ã© avec {index.ntotal} vecteurs")
        
        return index
    except Exception as e:
        print(f"âŒ Erreur lors de la crÃ©ation de l'index : {e}")
        return None

def save_artifacts(index, chunks, output_dir):
    """
    Sauvegarde l'index FAISS et les chunks
    """
    print(f"\nğŸ’¾ Sauvegarde des fichiers dans {output_dir}...")
    
    # CrÃ©er le dossier s'il n'existe pas
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # Sauvegarder l'index FAISS
        index_path = os.path.join(output_dir, 'faiss_index.index')
        faiss.write_index(index, index_path)
        print(f"âœ… Index FAISS sauvegardÃ© : {index_path}")
        
        # Sauvegarder les chunks
        chunks_path = os.path.join(output_dir, 'chunks.pkl')
        with open(chunks_path, 'wb') as f:
            pickle.dump(chunks, f)
        print(f"âœ… Chunks sauvegardÃ©s : {chunks_path}")
        
        # Sauvegarder les mÃ©tadonnÃ©es
        metadata = {
            'num_chunks': len(chunks),
            'embedding_model': EMBEDDING_MODEL,
            'chunk_size': CHUNK_SIZE,
            'dimension': index.d
        }
        
        metadata_path = os.path.join(output_dir, 'metadata.pkl')
        with open(metadata_path, 'wb') as f:
            pickle.dump(metadata, f)
        print(f"âœ… MÃ©tadonnÃ©es sauvegardÃ©es : {metadata_path}")
        
        return True
    except Exception as e:
        print(f"âŒ Erreur lors de la sauvegarde : {e}")
        return False

def test_search(index, chunks, model, test_query="Comment crÃ©er une vente?"):
    """
    Teste la recherche avec une question exemple
    """
    print(f"\nğŸ” Test de recherche avec : '{test_query}'")
    
    try:
        # Encoder la question
        query_embedding = model.encode([test_query])
        
        # Rechercher les 3 chunks les plus similaires
        distances, indices = index.search(query_embedding.astype('float32'), 3)
        
        print(f"\nğŸ“Š RÃ©sultats de la recherche :")
        for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
            print(f"\n  RÃ©sultat {i+1} (distance: {dist:.4f}):")
            chunk_preview = chunks[idx][:200].replace('\n', ' ')
            print(f"  {chunk_preview}...")
        
        return True
    except Exception as e:
        print(f"âŒ Erreur lors du test : {e}")
        return False

# ============== MAIN ==============

def main():
    """
    Fonction principale
    """
    print("=" * 60)
    print("ğŸš€ CRÃ‰ATION DES EMBEDDINGS POUR ADES CHATBOT")
    print("=" * 60)
    
    # 1. Charger la documentation
    documentation = load_documentation(DOC_PATH)
    if documentation is None:
        return
    
    # 2. DÃ©couper en chunks
    chunks = split_into_chunks(documentation, CHUNK_SIZE)
    if not chunks:
        print("âŒ Aucun chunk crÃ©Ã©")
        return
    
    # 3. CrÃ©er les embeddings
    embeddings, model = create_embeddings(chunks, EMBEDDING_MODEL)
    if embeddings is None:
        return
    
    # 4. CrÃ©er l'index FAISS
    index = create_faiss_index(embeddings)
    if index is None:
        return
    
    # 5. Sauvegarder
    success = save_artifacts(index, chunks, OUTPUT_DIR)
    if not success:
        return
    
    # 6. Tester
    test_search(index, chunks, model)
    
    print("\n" + "=" * 60)
    print("âœ… TERMINÃ‰ AVEC SUCCÃˆS !")
    print("=" * 60)
    print(f"\nğŸ“ Fichiers crÃ©Ã©s dans {OUTPUT_DIR}/")
    print("  - faiss_index.index (index de recherche)")
    print("  - chunks.pkl (morceaux de documentation)")
    print("  - metadata.pkl (informations)")
    print("\nğŸ‰ Vous pouvez maintenant passer Ã  l'intÃ©gration dans app.py")

if __name__ == "__main__":
    main()